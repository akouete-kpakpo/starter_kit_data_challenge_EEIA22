{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Summer School 2022 - Challenge Total Energies \n",
    "# Wind turbine production forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "from challenge.preprocessing import build_new_features, build_polynomial_wind_features\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "EXPORT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path.cwd()\n",
    "data_path = current_path / \"data\"\n",
    "output_path = current_path / \"outputs\"\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path / \"train.csv\", parse_dates=[\"date\"], index_col=[\"date\"]).sort_index()\n",
    "\n",
    "test = pd.read_csv(data_path / \"test.csv\", parse_dates=[\"date\"], index_col=[\"date\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.index.min() == pd.Timestamp('2009-07-01 01:00:00')\n",
    "assert data.index.max() == pd.Timestamp('2012-06-26 12:00:00')\n",
    "\n",
    "assert test.index.min() == pd.Timestamp('2011-01-01 01:00:00')\n",
    "assert test.index.max() == pd.Timestamp('2012-06-28 12:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "data.asfreq(\"h\").tail(36+48+36+48+36)[[\"ws\"]].plot(ax=ax)\n",
    "plt.title(\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "test.asfreq(\"h\").tail(36+48+36+48+36)[[\"ws\"]].plot(ax=ax)\n",
    "plt.title(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_data_shape = (18_756, 5)\n",
    "np.testing.assert_allclose(data.shape, expected_data_shape)\n",
    "\n",
    "expected_test_shape = (7_488, 4)\n",
    "np.testing.assert_allclose(test.shape, expected_test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we check that we have no NA values in the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not data.isnull().any(axis=None) and not test.isnull().any(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, our data is exactly the types we want, and no NA are present, we can pass on to an exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA and first models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking what we want to predict : the power measurement wp1 of the first farm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Target variable `Wp1`: the normalized power generated by one wind farm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "data[[\"wp1\"]].head(300).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"wp1\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(data[\"wp1\"].min(), 0.0)\n",
    "np.testing.assert_allclose(data[\"wp1\"].max(), 0.947)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Critical parameter in predicting the wind power, obviously seems to be the wind speed. Let us observe this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "data[[\"ws\"]].head(300).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is any correlation between power and speed by taking a look at one of them, function of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "data[[\"ws\", \"wp1\"]].head(300).plot.scatter(ax=ax, x=\"ws\", y=\"wp1\", xlabel=\"winspeed\", ylabel=\"windpower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There clearly seems to be a correlation between the two ! When windspeed rises, the wind power rises, on average, even if the relation between the two is not linear. \n",
    "\n",
    "We can confirm this by calculating the correlation coeficient betwen the two. Actually we can directly calculate all of the correlation coefficient between all variables in the dataset in one line of code. Let us do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient between windpseed and wind powe is 0.7 : this is very high indeed, our firt conclusion were true. Let us recall Pearson's definition of correlation, which is the one we used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sample, it is defined by : \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\sum \\limits _{i=1} ^{n} (x_{i} - \\bar x) (y_{i} - \\bar y)}{\\sqrt{\\sum \\limits _{i=1} ^{n}(x_{i} - \\bar x)^{2}}\\sqrt{\\sum \\limits _{i=1} ^{n}(y_{i} - \\bar y)^{2}}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is important to recall is that it is comprised in the range $[-1, 1]$ and : \n",
    "    - it is equal to 1 if the two variables are exactly the same\n",
    "    - -1 if the two varables are the exact opposite\n",
    "    - when it is equal to 0, the two variables have nothing in common : they are independent one from the other, for example this could be the value of the bitcoin and the average windspeed in south korea, we know these two have nothing in common.\n",
    "    - when it is > 0, the two variables are positively correlated, this means that on average, when one goes up, the other goes up too.\n",
    "    - when it is < 0, the two variables are negatively correlated, this means that on average, when one goes up, the other goes down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Model `wp1 ~ ws` relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this first EDA, a very simple model we can try to predict our sample is to try a linear model : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ wp_{1} = \\alpha . ws + \\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now cut our dataframe in two : one dataframe will be used for training, and the other one will be used to estimate what is the value of this first model we have made. \n",
    "For this, why do we not directly use the test set ? The reason is that for the test set, we do not know the exact value of the power measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = build_new_features(data)\n",
    "\n",
    "test = build_new_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Wind direction: `u` & `v`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "data[[\"sin_wd\"]].head(300).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that, as expected, it is comprised between 0 and 360. And when it crosses 360 it goes to 0, as expected for a direction. But this makes it a highly discontinuous function in 360. How should we treat this in the models ? That's a question for you to answer.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing about direction, the wind vector can be either expressed as :\n",
    "- windspeed, and wind direction, \n",
    "- or u and v components. \n",
    "\n",
    "These two representations are interchangeable (for math guys, there is a bijection between these two representations)\n",
    "And in our case, the convention for the wind direction used in our data is wind vector azimuth. For more information on these matters, please check the following website which explains these representations : \n",
    "    http://tornado.sfsu.edu/geosciences/classes/m430/Wind/WindDirection.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "data[[\"u\", \"v\"]].head(300).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data[\"u\"]**2 + data[\"v\"]**2, data[\"ws\"]**2], axis=1).plot(kind = \"scatter\", x=0, y=\"ws\")\n",
    "plt.xlabel(\"ws^2\")\n",
    "plt.ylabel(\"u^2 + v^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data[\"u\"], data[\"ws\"] * data[\"sin_wd\"]], axis=1).plot(kind = \"scatter\", x=\"u\", y=0)\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"ws * sin(wd)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Next steps Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([data, test]).sort_index()\n",
    "df_full[\"ws_t_1\"] = df_full[\"ws\"].shift()\n",
    "df_full[\"sin_wd_t_1\"] = df_full[\"sin_wd\"].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_full.loc[data.iloc[1:].index]\n",
    "test = df_full.loc[test.index].drop(\"wp1\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_wind_features = [\"ws_t_1\", \"ws\", \"sin_wd_t_1\", \"sin_wd\", \"u\", \"v\"]\n",
    "# selected_wind_features = [\"u\", \"v\"]\n",
    "selected_time_features = [\"hour\", \"day\", \"month\"]\n",
    "selected_features = selected_wind_features + selected_time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polynomial_data = build_polynomial_wind_features(\n",
    "    polynomial_features, data, selected_wind_features, selected_time_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_polynomial_data, data[\"wp1\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = build_polynomial_wind_features(\n",
    "    polynomial_features, test, selected_wind_features, selected_time_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [col for col in data.columns if col != \"wp1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(data, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"wp1\", axis=1)\n",
    "y_train = train[\"wp1\"]\n",
    "\n",
    "X_val = validation.drop(\"wp1\", axis=1)\n",
    "y_val = validation[\"wp1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(lm.predict(X_train[selected_features]), y_train))\n",
    "print(mean_absolute_error(lm.predict(X_val[selected_features]), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, data[selected_features], data[\"wp1\"], cv=5, scoring=mae_scorer)\n",
    "print(scores)\n",
    "print(-scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice ! We have our first model and it gives an error of 0.13 !..\n",
    "\n",
    "Now wait, what is the value of that first model ? How can we know if 0.13 is actually a good error ? Well for this, a very neat way to be able to know if our model is worth anything is to compare it to a naive model. A naive model can be for example to predict everytime the same value, whatever the conditions. One of these naive model we have at hand would be to predict the mean value of the wind power in the train set. Let's see what would this model give. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyRegressor(strategy='mean')\n",
    "dm.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(dm.predict(X_train[selected_features]), y_train))\n",
    "print(mean_absolute_error(dm.predict(X_val[selected_features]), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyRegressor(strategy='median')\n",
    "dm.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(dm.predict(X_train[selected_features]), y_train))\n",
    "print(mean_absolute_error(dm.predict(X_val[selected_features]), y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes ! Good news, our model did really learn something good ! We are a lot better than the 'mean' or 'median' model, around 30% better, based on this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen first models above : the linear model with one variable (windspeed), and two naive models (median, and mean). It will be your job from now on to determine the best model, but let's already take a look at one classic model that data scientists usually try on for nearly any subject : Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, max_depth=4)\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "scores = cross_val_score(rf, data[selected_features], data[\"wp1\"], cv=5, scoring=mae_scorer)\n",
    "print(-scores)\n",
    "print(-scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm = LGBMRegressor()\n",
    "lgbm = LGBMRegressor(n_estimators=100, max_depth=3)\n",
    "\n",
    "lgbm.fit(X_train[selected_features], y_train)\n",
    "\n",
    "scores = cross_val_score(lgbm, data[selected_features], data[\"wp1\"], cv=5, scoring=mae_scorer)\n",
    "print(-scores)\n",
    "print(-scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest does only very slightly better than the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(data[selected_features], data[\"wp1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our model is fit, we can pass on to the predictions.\n",
    "\n",
    "_Note: be careful when generating your submission file. Indeed, it needs to be a csv file with \";\" as separator._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[selected_features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.copy()\n",
    "\n",
    "df_predictions = pd.DataFrame({\n",
    "    \"wp1\": lgbm.predict(X_test[selected_features]),\n",
    "}, index=test.index)\n",
    "\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT:\n",
    "    df_predictions.to_csv(output_path / \"predictions.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn, what better model can you think of ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
